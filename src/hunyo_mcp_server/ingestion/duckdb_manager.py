#!/usr/bin/env python3
"""
DuckDB Manager - Database initialization and connection management.

Handles DuckDB database setup, schema creation, and connection pooling
for the Hunyo MCP Server ingestion pipeline.
"""

import json
from pathlib import Path
from typing import Any, Dict, List, Optional

import duckdb

# Import project paths
from ..config import get_repository_root

# Import logging utility
try:
    from ...capture.logger import get_logger

    db_logger = get_logger("hunyo.duckdb")
except ImportError:
    # Fallback for testing
    class SimpleLogger:
        def status(self, msg):
            print(f"[STATUS] {msg}")

        def success(self, msg):
            print(f"[SUCCESS] {msg}")

        def warning(self, msg):
            print(f"[WARNING] {msg}")

        def error(self, msg):
            print(f"[ERROR] {msg}")

        def config(self, msg):
            print(f"[CONFIG] {msg}")

        def startup(self, msg):
            print(f"[STARTUP] {msg}")

    db_logger = SimpleLogger()


class DuckDBManager:
    """
    Manages DuckDB database initialization, connections, and schema setup.

    Features:
    - Automatic schema initialization from SQL files
    - Connection management and reuse
    - Query execution with error handling
    - Transaction support for batch operations
    """

    def __init__(self, database_path: Path):
        self.database_path = Path(database_path)
        self.connection: duckdb.DuckDBPyConnection | None = None
        self._schema_initialized = False

        # Ensure database directory exists
        self.database_path.parent.mkdir(parents=True, exist_ok=True)

        db_logger.status("DuckDB Manager initialized")
        db_logger.config(f"Database path: {self.database_path}")

    def initialize_database(self) -> None:
        """Initialize database and create schema from SQL files."""
        if self._schema_initialized:
            db_logger.warning("Database already initialized")
            return

        db_logger.startup("ğŸ”„ Initializing DuckDB database and schema...")

        try:
            # Connect to database
            self._connect()

            # Execute schema initialization
            self._create_schema()

            # Verify schema creation
            self._verify_schema()

            self._schema_initialized = True
            db_logger.success("âœ… Database schema initialized successfully")

        except Exception as e:
            db_logger.error(f"Failed to initialize database: {e}")
            raise

    def _connect(self) -> None:
        """Establish database connection."""
        if self.connection:
            return

        try:
            self.connection = duckdb.connect(str(self.database_path))
            db_logger.success(f"Connected to database: {self.database_path}")
        except Exception as e:
            db_logger.error(f"Failed to connect to database: {e}")
            raise

    def _create_schema(self) -> None:
        """Create database schema from SQL files."""
        # Get project root and schema directory
        project_root = get_repository_root()
        schema_dir = project_root / "schemas" / "sql"

        if not schema_dir.exists():
            raise FileNotFoundError(f"Schema directory not found: {schema_dir}")

        # Execute main initialization script
        init_script = schema_dir / "init_database.sql"
        if init_script.exists():
            db_logger.config(f"Executing schema: {init_script.name}")
            self._execute_sql_file(init_script)
        else:
            # Fallback: execute individual schema files
            db_logger.warning("Main init script not found, using individual files")

            schema_files = ["runtime_events_table.sql", "openlineage_events_table.sql"]

            for filename in schema_files:
                file_path = schema_dir / filename
                if file_path.exists():
                    db_logger.config(f"Executing schema: {filename}")
                    self._execute_sql_file(file_path)
                else:
                    db_logger.warning(f"Schema file not found: {filename}")

            # Create views
            views_dir = schema_dir / "views"
            if views_dir.exists():
                for view_file in views_dir.glob("*.sql"):
                    db_logger.config(f"Creating view: {view_file.name}")
                    self._execute_sql_file(view_file)

    def _execute_sql_file(self, file_path: Path) -> None:
        """Execute SQL commands from a file."""
        try:
            with open(file_path) as f:
                sql_content = f.read()

            # Split on semicolons and execute each statement
            statements = [
                stmt.strip() for stmt in sql_content.split(";") if stmt.strip()
            ]

            for statement in statements:
                if statement and not statement.startswith("--"):
                    self.connection.execute(statement)

        except Exception as e:
            db_logger.error(f"Failed to execute SQL file {file_path}: {e}")
            raise

    def _verify_schema(self) -> None:
        """Verify that required tables and views exist."""
        required_tables = ["runtime_events", "lineage_events"]
        required_views = ["vw_lineage_io", "vw_performance_metrics"]

        # Check tables
        for table in required_tables:
            try:
                result = self.connection.execute(
                    f"SELECT COUNT(*) FROM {table}"
                ).fetchone()
                db_logger.success(f"âœ“ Table '{table}' exists and accessible")
            except Exception as e:
                db_logger.error(f"âœ— Table '{table}' verification failed: {e}")
                raise

        # Check views (optional - they might not all exist yet)
        for view in required_views:
            try:
                result = self.connection.execute(
                    f"SELECT COUNT(*) FROM {view}"
                ).fetchone()
                db_logger.success(f"âœ“ View '{view}' exists and accessible")
            except Exception:
                db_logger.warning(f"âš  View '{view}' not found (may be created later)")

    def execute_query(
        self, query: str, parameters: list | None = None
    ) -> list[dict[str, Any]]:
        """Execute a query and return results as list of dictionaries."""
        self._ensure_connected()

        try:
            if parameters:
                result = self.connection.execute(query, parameters)
            else:
                result = self.connection.execute(query)

            # Convert to list of dictionaries
            columns = (
                [desc[0] for desc in result.description] if result.description else []
            )
            rows = result.fetchall()

            return [dict(zip(columns, row, strict=False)) for row in rows]

        except Exception as e:
            db_logger.error(f"Query execution failed: {e}")
            db_logger.error(f"Query: {query}")
            raise

    def insert_runtime_event(self, event_data: dict[str, Any]) -> None:
        """Insert a runtime event into the database."""
        query = """
        INSERT INTO runtime_events (
            event_type, execution_id, cell_id, cell_source, cell_source_lines,
            start_memory_mb, end_memory_mb, duration_ms, timestamp, 
            session_id, emitted_at, error_info
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """

        parameters = [
            event_data.get("event_type"),
            event_data.get("execution_id"),
            event_data.get("cell_id"),
            event_data.get("cell_source"),
            event_data.get("cell_source_lines"),
            event_data.get("start_memory_mb"),
            event_data.get("end_memory_mb"),
            event_data.get("duration_ms"),
            event_data.get("timestamp"),
            event_data.get("session_id"),
            event_data.get("emitted_at"),
            (
                json.dumps(event_data.get("error_info"))
                if event_data.get("error_info")
                else None
            ),
        ]

        self._ensure_connected()
        self.connection.execute(query, parameters)

    def insert_lineage_event(self, event_data: dict[str, Any]) -> None:
        """Insert a lineage event into the database."""
        query = """
        INSERT INTO lineage_events (
            run_id, execution_id, event_type, job_name, event_time,
            duration_ms, session_id, emitted_at, inputs_json, outputs_json,
            column_lineage_json, column_metrics_json, other_facets_json
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """

        parameters = [
            event_data.get("run_id"),
            event_data.get("execution_id"),
            event_data.get("event_type"),
            event_data.get("job_name"),
            event_data.get("event_time"),
            event_data.get("duration_ms"),
            event_data.get("session_id"),
            event_data.get("emitted_at"),
            (
                json.dumps(event_data.get("inputs_json"))
                if event_data.get("inputs_json")
                else None
            ),
            (
                json.dumps(event_data.get("outputs_json"))
                if event_data.get("outputs_json")
                else None
            ),
            (
                json.dumps(event_data.get("column_lineage_json"))
                if event_data.get("column_lineage_json")
                else None
            ),
            (
                json.dumps(event_data.get("column_metrics_json"))
                if event_data.get("column_metrics_json")
                else None
            ),
            (
                json.dumps(event_data.get("other_facets_json"))
                if event_data.get("other_facets_json")
                else None
            ),
        ]

        self._ensure_connected()
        self.connection.execute(query, parameters)

    def get_table_info(self, table_name: str) -> list[dict[str, Any]]:
        """Get information about a table's structure."""
        query = f"DESCRIBE {table_name}"
        return self.execute_query(query)

    def get_table_count(self, table_name: str) -> int:
        """Get the number of rows in a table."""
        query = f"SELECT COUNT(*) as count FROM {table_name}"
        result = self.execute_query(query)
        return result[0]["count"] if result else 0

    def begin_transaction(self) -> None:
        """Begin a database transaction."""
        self._ensure_connected()
        self.connection.begin()

    def commit_transaction(self) -> None:
        """Commit the current transaction."""
        self._ensure_connected()
        self.connection.commit()

    def rollback_transaction(self) -> None:
        """Rollback the current transaction."""
        self._ensure_connected()
        self.connection.rollback()

    def _ensure_connected(self) -> None:
        """Ensure database connection is active."""
        if not self.connection:
            self._connect()

    def close(self) -> None:
        """Close the database connection."""
        if self.connection:
            self.connection.close()
            self.connection = None
            db_logger.config("Database connection closed")

    def __enter__(self):
        """Context manager entry."""
        self._ensure_connected()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit."""
        self.close()


# Convenience functions for testing and CLI usage
def create_test_database(database_path: Path) -> DuckDBManager:
    """Create a test database with schema for development/testing."""
    manager = DuckDBManager(database_path)
    manager.initialize_database()
    return manager


def get_database_stats(database_path: Path) -> dict[str, Any]:
    """Get basic statistics about the database."""
    with DuckDBManager(database_path) as db:
        db.initialize_database()

        stats = {
            "runtime_events_count": db.get_table_count("runtime_events"),
            "lineage_events_count": db.get_table_count("lineage_events"),
            "database_size_bytes": (
                database_path.stat().st_size if database_path.exists() else 0
            ),
            "database_path": str(database_path),
        }

        return stats
